%\VignetteIndexEntry{SimulatorZ}
%\VignetteDepends{simulatorZ, superpc, curatedOvarianData}
%\VignetteKeywords{}
%\VignettePackage{superpc, curatedOvarianData}


\documentclass[a4paper, 10pt]{article}
\usepackage[authoryear,round]{natbib}
<<style-Sweave, eval=TRUE, echo=FALSE, results=tex>>=
BiocStyle::latex() 
@
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{latexsym}
\usepackage{verbatim}
\usepackage{epsfig}
\usepackage{fleqn}
\usepackage{color}
\usepackage{mathrsfs}
\usepackage{eufrak}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{amsbsy}
\usepackage{bm}

\parindent0pt
\parskip1ex
\oddsidemargin-0.5cm
\topmargin-.2cm
\textheight23cm
\textwidth13cm
\headsep0.5cm
\pagestyle{plain}

\def\su{\sum_{i=1}^n}
\def\etall{\mbox{{\it et al., }}}
\def\etal{\mbox{{\it et al. }}}


\bioctitle{SimulatorZ package vignette}
\author{Yuqing Zhang\footnote{zhangyuqing.pkusms@gmail.com}, Christoph Bernau\footnote{Christoph.Bernau@lrz.de},Levi Waldron\footnote{levi.waldron@hunter.cuny.edu}}


\begin{document}
\date{Edited: August 2014; Compiled: \today}

\maketitle
\tableofcontents

<<options, echo=FALSE>>=  
options(width=72)
@

\section{Introduction}


\section{Evaluating the true models of Data sets}
The parametric-bootstrap step involves a generative model that combines the truncated inversion method in Bender et al. (2005) , the Nelson-Aalen estimator for cumulative hazard functions, and  CoxBoost method (Binder and Schumacher, 2008) to simulate survival times. These generative models are referred to as the "true models" of the data sets. True models can give a brief description of the studies we will evaluate from multiple aspects and the following are some examples.

\section{C Index of true linear predictor}
True linear predictors are calculated by multiplying the gene expression matrix with coefficients we used to simulate the survival times. C indices we get with true linear predictors should set the upper bound of the validation performance that any algorithms can reach.
<<echo=T,results=hide>>=
## Construct the set and response list
library(simulatorZ)
library(curatedOvarianData)
data(E.MTAB.386_eset)
esets <- list(E.MTAB.386_eset)
time <- esets[[1]]$days_to_death
cens <- esets[[1]]$vital_status
new_cens <- numeric(length(cens))
for(i in 1:length(cens)){
  if(cens[i]=="living") new_cens[i] <- 1
  else new_cens[i] <- 0
}
y.var <- Surv(time, new_cens)
y.vars.list <- list(y.var)

### perform the model in three steps 
result <- getTrueModel(esets=esets, y.vars=y.vars.list, parstep=100)
simmodel <- simData(esets=esets, y.vars=y.vars.list, n.samples=4000)
new_simmodel <- simTime(simmodels=simmodel, result=result)

### Or by one function simBootstrap
new_simmodel <- simBootstrap(esets=esets, y.vars=y.vars.list, 
                             n.samples=4000, parstep=100)
new_esets <- new_simmodel$esets
indices <- new_simmodel$indices
beta <- result$beta
lp <- result$lp
lpboot <- lp[[1]][indices[[1]]]
@
<<echo=T>>=
timetest <- time[indices[[1]]]
censtest <- new_cens[indices[[1]]]
yboot <- Surv(timetest, censtest)
print(paste("c index = ", 
            rcorr.cens(-lpboot, yboot)[1], 
            sep=""))
@

\subsection{Compare baseline hazard on bootstrapped data set to baseline hazard on original data using the true lp}
<<cumhaz,echo=T,fig=T,include=FALSE>>=
grid <- result$grid[[1]]
plot(basehaz.gbm(t=yboot[,1], delta=yboot[,2],
                 f.x=lpboot, t.eval = grid, 
                 smooth = TRUE, cumulative = T),
     type='l',col='blue',main='cumulative survival hazard',
     ylab='Cumulative Hazard',xlab='time',lty=3)
  legend('topleft',c('estimated on real data using model lp',
                     'estimated on simulated data using model lp'),
         col=c('blue','red'),pch=15,cex=0.6)
lines(result$survH[[1]],col='red',lty=2)
@  
\incfig{simulatorZ-vignette-cumhaz}{0.8\textwidth}{Cumulative hazard of original and simulated data sets.}
{Two lines are almost the same.}


\subsection{distribution of the true linear predictor}
<<lp,echo=T,fig=TRUE>>=
boxplot(lp)
@ 

\subsection{Plots on estimated survival functions}
<<survfun,echo=T,fig=T,include=FALSE>>=
survH.sim <- censH.sim <- list()
for(i in 1:length(new_esets)){
    id <- new_simmodel$setsID[i]
    lp <- t(exprs(new_esets[[i]]))  %*% as.matrix(beta[[id]])
    time.sim <- new_simmodel$y.vars.list[[i]][, 1]
    status.sim <- new_simmodel$y.vars.list[[i]][, 2]    
    grid <- seq(0, max(time.sim[time.sim!=1e+08]), by = 1)
    survH.sim[[i]] <- basehaz.gbm(t=time.sim, delta=status.sim, 
                                  f.x=lp, t.eval=grid, 
                                  smooth=TRUE, cumulative=TRUE)
    inverse_status.sim <- (-1) * status.sim + 1
    censH.sim[[i]] <- basehaz.gbm(t=time.sim, delta=inverse_status.sim,
                                  f.x=rep(0, length(time.sim)), t.eval=grid,
                                  smooth=TRUE, cumulative=TRUE)        
    plotind <- sample(1:4000, 500, replace=FALSE)
    for(j in plotind){
      color <- sample(1:8, 1)
      plot(exp(-survH.sim[[i]]*exp(lp[j])), type="l", 
           xlim=c(0, 3000), ylim=c(0, 1), xlab="time", 
           ylab="probability of survival", 
           main="estimated survival functions", 
           col=color)
      par(new=TRUE)
    }    
  }
@
\incfig{simulatorZ-vignette-survfun}{0.8\textwidth}{Survival curves of the simulated observations.}
{Through examining the survival curves of simulated observations, we can see that there is enough variance amongst the simulated data set, thus ensuring the similarity between simulated and real data sets. This is important for further validation.}


\section{Independent within study validation (Superpc)}
Other than inspecting true models of the simulated data sets, we can introduce in various algorithms and conduct validation with them. The following example shows how to use SuperPC (Blair and
Tibshirani, 2004) algorithm to train and validate on one ExpressionSet
\subsection{create training set and large validation set}
<<echo=TRUE,results=hide>>=
tr.size <- 450
simmodel.tr <- simData(esets, tr.size)
tr.set <- simmodel.tr$esets[[1]]
X.tr <- t(exprs(tr.set))
time.tr <- time[simmodel.tr$indices[[1]]]
status.tr <- new_cens[simmodel.tr$indices[[1]]]
y.tr <- Surv(time.tr, status.tr)
rm(time.tr, status.tr, simmodel.tr)

# validation set
val.size <- 1000
simmodel.val <- simData(esets, val.size)
val.set <- simmodel.val$esets[[1]]
X.val <- t(exprs(val.set))
time.val <- time[simmodel.val$indices[[1]]]
status.val <- new_cens[simmodel.val$indices[[1]]]
y.val <- Surv(time.val, status.val)
rm(time.val, status.val)
@
<<echo=TRUE>>=
#check C-Index for true lp
val.par <- getTrueModel(esets, y.vars.list, 100)
lpboot <- val.par$lp[[1]][simmodel.val$indices[[1]]]
c.ind <- rcorr.cens(-lpboot, y.val)[1]
print(c.ind)
@

\subsection{Fit Superpc}
<<echo=TRUE,fig=TRUE,results=hide>>=
library(superpc)
###fit on training set (with parameter tuning)
tr.data<- data<-list(x=t(X.tr),y=y.tr[,1], censoring.status=y.tr[,2], 
                     featurenames=colnames(X.tr))
#fit
fit.tr<-superpc.train(data=tr.data,type='survival')
#tuning
cv.tr<-superpc.cv(fit.tr,data=tr.data)
#get best pars
n.comp<-which.max(apply(cv.tr$scor, 1, max, na.rm = TRUE))
thresh<-cv.tr$thresholds[which.max(cv.tr$scor[n.comp, ])]
#fit using optimal parameters
#compute lp using the optimal parameters
lp.tr<- superpc.predict(fit.tr, tr.data, tr.data, threshold=thresh, 
                        n.components=n.comp)$v.pred.1df
#plot distribution of lp
boxplot(lp.tr)
@ 

\subsection{validation on large validation set}
<<echo=T>>=
#predict lp for val. data
data.val<- data<-list(x=t(X.val),y=y.val[,1], censoring.status=y.val[,2], 
                      featurenames=colnames(X.tr))
lp.val<-superpc.predict(fit.tr, tr.data, data.val, threshold=thresh, 
                        n.components=n.comp)$v.pred.1df

#compute C-Index
print('C-Index')
(c.ind<-rcorr.cens(-lp.val,y.val)[1])
#compute correlation to true lp
print('correlation to true lp')
(corlps<-cor(lp.val,lpboot,method='pearson'))
@ 

\section{Cross Study Validation}
With enough data sets, we can perform cross validation on one set as illustrated in the last section, or do cross study validation with multiple sets. For specific training and validation set, we can simply replace the validation set in the last section with the testing set. If we hope to perform cross study validation between each pair of data sets, the simulatorZ has a function zmatrix() to generate a matrix of C-Index. For the diagnostic elements, it performs within study cross validation. 
\subsection{Generate a matrix of validation statistics with original data sets}

<<echo=TRUE,results=hide>>=
data( E.MTAB.386_eset )
eset1 <- E.MTAB.386_eset[1:100, 1:30]
eset2 <- E.MTAB.386_eset[1:100, 31:60]
eset3 <- E.MTAB.386_eset[1:100, 61:90]  
esets <- list(eset1, eset2, eset3) 
  
time1 <- eset1$days_to_death
cens1 <- sample(0:1, 30, replace=TRUE)
y1 <- Surv(time1, cens1)
time2 <- eset2$days_to_death
cens2 <- sample(0:1, 30, replace=TRUE)
y2 <- Surv(time2, cens2)
time3 <- eset3$days_to_death
cens3 <- sample(0:1, 30, replace=TRUE)
y3 <- Surv(time3, cens3)
y.vars <- list(y1, y2, y3)

z <- zmatrix(esets=esets,y.vars=y.vars,
             fold=3,trainingFun=plusMinus)
@
<<echo=TRUE>>=
print(z)
@

\subsection{Generate a matrix of validation statistics with simulated data sets}
Now, we can also combine the simulation with generating the matrix of C statistics like below.
<<echo=TRUE,results=hide>>=
Z.list <- list()
CV <- CSV <- c()
for(b in 1:30){
  print(paste("iteration: ", b, sep=""))
  sim2.esets <- simBootstrap(esets=esets, n.samples=150, y.vars=y.vars,
                             parstep=100, type="two-steps")
  Z.list[[b]] <- zmatrix(esets=sim2.esets$esets.list, 
                         y.vars=sim2.esets$y.vars.list, fold=4,
                         trainingFun=plusMinus)
  sum.cv <- 0
  for(i in 1:length(esets)){
    sum.cv <- sum.cv + Z.list[[b]][i, i]
  }
  CV[b] <- sum.cv / length(esets)
  CSV[b] <- (sum(Z.list[[b]]) - sum.cv) / (length(esets)*(length(esets)-1))
}
@

<<box,echo=TRUE,fig=TRUE,include=FALSE>>=
average.Z <- Z.list[[1]]
for(i in 2:length(Z.list)){
  average.Z <- average.Z + Z.list[[i]]
}
average.Z <- average.Z / 30
print(average.Z)

resultlist <- list(CSV=CSV, CV=CV)
boxplot(resultlist, col=c("white", "grey"), ylab="C-Index", 
        boxwex = 0.25, xlim=c(0.5, 2.5))
@
\incfig{simulatorZ-vignette-box}{0.8\textwidth}{Boxplots of C-Index performance with cross validation and cross study validation}



\section{Session Info}
<<echo=T>>=
toLatex(sessionInfo())
@ 

\end{document}